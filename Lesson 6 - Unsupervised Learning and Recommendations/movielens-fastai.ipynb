{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756f664b",
   "metadata": {},
   "source": [
    "# \"How's that movie?\" -  Collaborative filtering with FastAI\n",
    "\n",
    "*Build a state-of-the-art movie recommendation system with just 10 lines of code*\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1200/1*UCnwjtYoYoJtWM7DxzRT0A.jpeg\" style=\"width:480px;\"/>\n",
    "\n",
    "Recommender systems are at the core of pretty much every online service we interact with. Social networking sites like Facebook, Twitter and Instagram recommend posts you might like, or people you might know. Video streaming services like YouTube and Netflix recommend videos, movies or TV shows you might like. Online shopping sites like Amazon recommend products you might want to buy. \n",
    "\n",
    "**Collaborative** filtering is perhaps the most common technique used by recommender systems.\n",
    "\n",
    "> *Collaborative filtering is a method of making predictions about the interests of a user by collecting preferences from many users. The underlying assumption is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue than that of a randomly chosen person.* - [Wikipedia](https://medium.com/r/?url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FCollaborative_filtering)\n",
    "\n",
    "The [librec](https://medium.com/r/?url=https%3A%2F%2Fwww.librec.net%2F) Java library provides [over 70 different algorithms](https://medium.com/r/?url=https%3A%2F%2Fwww.librec.net%2Fdokuwiki%2Fdoku.php%3Fid%3DAlgorithmList%23recommender_algorithm_list) for collaborative filtering. In this post however, we'll implement a relatively new technique called *neural collaborative filtering*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da46a9ac",
   "metadata": {},
   "source": [
    "## The MovieLens 100K Dataset\n",
    "\n",
    "The [MovieLens 100K dataset](https://grouplens.org/datasets/movielens/) is a collection of movie ratings by 943 users on 1682 movies. There are 100,000 ratings in total, since not every user has seen and rated every movie. Here are some sample ratings from the dataset:\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*OZLI7a0ueujHzj5NG3oRlQ.png\" style=\"width:360px\" />\n",
    "\n",
    "Every user is given a unique numeric ID (ranging from 1 to 943), and each movie is given a unique numeric ID too (ranging from 1 to 1682). User's ratings for movies are integers ranging from 1 to 5, with 5 being the highest.\n",
    "\n",
    "Our objective here is to build a *model* that can predict how a user would rate a movie they haven't already seen, by looking at the movie ratings of other users with similar tastes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01ea00c",
   "metadata": {},
   "source": [
    "## System Setup\n",
    "\n",
    "If you want to follow along and run the code as you read, you can clone this notebook, install the required dependencies using [conda](https://conda.io), and start Jupyter by running the following commands on the terminal:\n",
    "\n",
    "```\n",
    "pip install jovian --upgrade     # Install the jovian library \n",
    "jovian clone 5bc23520933b4cc187cfe18e5dd7e2ed # Download notebook\n",
    "cd movielens-fastai              # Enter the created directory \n",
    "jovian install                   # Install the dependencies\n",
    "conda activate movielens-fastai  # Activate virtual environment\n",
    "jupyter notebook                 # Start Jupyter\n",
    "```\n",
    "\n",
    "Make sure you have [conda](https://conda.io) installed before running the above commands. You can also click on the **\"Run on Binder\"** button at the top to start a Jupyter notebook server hosted on mybinder.org  instantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe51fe20",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "\n",
    "You can download the MovieLens 100K dataset [from this link](https://medium.com/r/?url=http%3A%2F%2Ffiles.grouplens.org%2Fdatasets%2Fmovielens%2Fml-100k.zip). Once downloaded, unzip and extract the data into a directory ml-100k next to the Jupyter notebook. As described in the [README](https://medium.com/r/?url=http%3A%2F%2Ffiles.grouplens.org%2Fdatasets%2Fmovielens%2Fml-100k-README.txt), the file u.data contains the list of ratings.\n",
    "\n",
    "*On Linux and Mac, you can simply run the follwing cell to download and extract the data:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde848cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "unzip:  cannot find or open ml-100k.zip, ml-100k.zip.zip or ml-100k.zip.ZIP.\n",
      "ls: cannot access 'ml-100k': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Download and extract the data (only for Linux and Mac)\n",
    "!rm -rf ml-100k ml-100k.zip\n",
    "!wget -q http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!unzip -q ml-100k.zip\n",
    "!ls ml-100k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92dd981",
   "metadata": {},
   "source": [
    "We begin the importing the required modules from Pandas and FastAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1f39809",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CollabDataBunch' from 'fastai.collab' (C:\\Users\\mmuqt\\.conda\\envs\\deeplearning\\lib\\site-packages\\fastai\\collab.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-3da2c3b793a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCollabDataBunch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollab_learner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'CollabDataBunch' from 'fastai.collab' (C:\\Users\\mmuqt\\.conda\\envs\\deeplearning\\lib\\site-packages\\fastai\\collab.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fastai.collab import CollabDataBunch, collab_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6ceb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46db3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
